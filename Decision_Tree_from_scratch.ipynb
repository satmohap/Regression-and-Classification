{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">**Decision Tree Implementation**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data From File  ,  Importing Packages , Converting all the values to Float from String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from math import log\n",
    "os.chdir(\"C:/Users/Satya/Files\")\n",
    "# Load data set\n",
    "with open(\"wine-dataset.csv\") as f:\n",
    "    next(f, None)\n",
    "    data = [list(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "data =np.array(data,float)\n",
    "print (\"Number of records: %d\" % len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data into Train-Test  ( 75%  Train &  25% Test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # Split training/test sets\n",
    "    # You need to modify the following code for cross validation.\n",
    "    K = 4\n",
    "    training_set = [x for i, x in enumerate(data) if i % K != 3]\n",
    "    test_set = [x for i, x in enumerate(data) if i % K == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating Function to bin Feature Values to create multiple thresholds for finding the best condition for Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binned_vals(rows, col):\n",
    "    values= set([row[col] for row in rows])\n",
    "    return list(np.histogram([float(i) for i in values],bins=10)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counting class labels for a dataset or subset of data arriving at a Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    counts = {}  \n",
    "    for row in rows:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Calculating Entropy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entropy_Calc(rows):\n",
    "    counts = class_counts(rows)\n",
    "    entropy = 0\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        entropy -= prob_of_lbl * log(prob_of_lbl, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Function for Creating Evaluation Criterias for various theresholds for Any Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Eval_Criteria:\n",
    "    \n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def Eval(self, example):\n",
    "        val = example[self.column]\n",
    "        return val >= self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Function for binary univariate split for the  Data Set / Subset of Data  at a Decision Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Splits(rows, Evals_Criteria):\n",
    "    right_rows, left_rows = [], []\n",
    "    for row in rows:\n",
    "        if Evals_Criteria.Eval(row):\n",
    "            right_rows.append(row)\n",
    "        else:\n",
    "            left_rows.append(row)\n",
    "    return right_rows, left_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Function for Calculating Information Gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_entropy):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_entropy - p * Entropy_Calc(left) - (1 - p) * Entropy_Calc(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Finding Best Split or Evaluation Criteria  at each node by calculating Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    best_gain = 0  \n",
    "    best_eval_criteria = None  \n",
    "    current_entropy = Entropy_Calc(rows)\n",
    "    n_features = len(rows[0]) - 1  \n",
    "\n",
    "    for col in range(n_features):  \n",
    "        values = binned_vals(rows,col) \n",
    "\n",
    "        for val in values:  # for each value\n",
    "            Evals_Criteria = Eval_Criteria(col, val)\n",
    "            right_rows, left_rows = Splits(rows, Evals_Criteria)\n",
    "            \n",
    "            if len(right_rows) == 0 or len(left_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = info_gain(right_rows, left_rows, current_entropy)\n",
    "\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_eval_criteria = gain, Evals_Criteria\n",
    "\n",
    "    return best_gain, best_eval_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for Prediction Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Prediction_Node:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = float(list(str(list(str(class_counts(rows).keys()).split('['))[1]).split(']'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for Decision Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self,\n",
    "                 Evals_Criteria,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.Evals_Criteria = Evals_Criteria\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Building the Tree recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    gain, Evals_Criteria = find_best_split(rows)\n",
    "    if gain == 0:\n",
    "        return Prediction_Node(rows)\n",
    "    true_rows, false_rows = Splits(rows, Evals_Criteria)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(Evals_Criteria, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the Function to  Build the Tree recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tree = build_tree(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Classifying Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    if isinstance(node, Prediction_Node):\n",
    "        return node.predictions\n",
    "    if node.Evals_Criteria.Eval(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Test set which is  25% of toal Data Set is 83.16993464052288\n"
     ]
    }
   ],
   "source": [
    "results= []\n",
    "for row in test_set:\n",
    "    result = classify(row, my_tree)\n",
    "    results.append( result == row[-1])\n",
    "accuracy = float(results.count(True))/float(len(results))\n",
    "print ( \"The Accuracy for Test set which is  25% of toal Data Set is\" , accuracy *100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:blue\">Conclusion</span>\n",
    "\n",
    "#### <span style=\"color:blue\">Above is the Decision Tree Algorithm .  The Accuracy for Test set which is  25% of toal Data Set is 83.17 % </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">**Cross-Validation**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for  1  iteration of Cross-Validation is  86.93877551020408 %\n",
      " The accuracy for  2  iteration of Cross-Validation is  83.06122448979592 %\n",
      " The accuracy for  3  iteration of Cross-Validation is  84.08163265306122 %\n",
      " The accuracy for  4  iteration of Cross-Validation is  85.3061224489796 %\n",
      " The accuracy for  5  iteration of Cross-Validation is  84.48979591836735 %\n",
      " The accuracy for  6  iteration of Cross-Validation is  83.06122448979592 %\n",
      " The accuracy for  7  iteration of Cross-Validation is  84.28571428571429 %\n",
      " The accuracy for  8  iteration of Cross-Validation is  82.82208588957054 %\n",
      " The accuracy for  9  iteration of Cross-Validation is  81.18609406952966 %\n"
     ]
    }
   ],
   "source": [
    "    K = 10\n",
    "    lst = np.arange(1,10)\n",
    "    accuracy = []\n",
    "    for j in lst:\n",
    "        training_set = [x for i, x in enumerate(data) if i % K != j]\n",
    "        test_set = [x for i, x in enumerate(data) if i % K == j]\n",
    "        my_tree = build_tree(training_set)\n",
    "        results= []\n",
    "        for row in test_set:\n",
    "            result = classify(row, my_tree)\n",
    "            results.append( result == row[-1])\n",
    "        accuracy.append(float(results.count(True))/float(len(results)))\n",
    "        print ( \" The accuracy for \" , j , \" iteration of Cross-Validation is \" , float(results.count(True))/float(len(results))*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average accuracy for Cross-Validation is  83.9147410839 %\n"
     ]
    }
   ],
   "source": [
    "print ( \"The Average accuracy for Cross-Validation is \" , np.average(accuracy)*100 , \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Conclusion</span>\n",
    "\n",
    "#### <span style=\"color:blue\">Above is the implementation of Cross Validation for 10 Folds .  The Average accuracy for Cross-Validation is  83.92 % </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">** Improvement Strategies**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Strategy 1 :- Using Gini Index Instead of Entropy</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Calculating Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gini_index_Calc(rows):\n",
    "    counts = class_counts(rows)\n",
    "    Gini_index = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        Gini_index -= prob_of_lbl**2\n",
    "    return Gini_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for Calculating Information Gain for Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_gain_gini(left, right, current_Gini_index):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_Gini_index - p * Gini_index_Calc(left) - (1 - p) * Gini_index_Calc(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Finding Best Split or Evaluation Criteria  at each node by calculating Information Gain for Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    best_gain = 0  \n",
    "    best_eval_criteria = None  \n",
    "    current_Gini_index = Gini_index_Calc(rows)\n",
    "    n_features = len(rows[0]) - 1  \n",
    "\n",
    "    for col in range(n_features):  \n",
    "        values = binned_vals(rows,col) \n",
    "\n",
    "        for val in values:  # for each value\n",
    "            Evals_Criteria = Eval_Criteria(col, val)\n",
    "            right_rows, left_rows = Splits(rows, Evals_Criteria)\n",
    "            \n",
    "            if len(right_rows) == 0 or len(left_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = info_gain_gini(right_rows, left_rows, current_Gini_index)\n",
    "\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_eval_criteria = gain, Evals_Criteria\n",
    "\n",
    "    return best_gain, best_eval_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tree = build_tree(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results= []\n",
    "for row in test_set:\n",
    "    result = classify(row, my_tree)\n",
    "    results.append( result == row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Test set which is  25% of toal Data Set is 82.0040899795501\n"
     ]
    }
   ],
   "source": [
    "accuracy = float(results.count(True))/float(len(results))\n",
    "print ( \"The Accuracy for Test set which is  25% of toal Data Set is\" , accuracy *100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for  1  iteration of Cross-Validation is  84.08163265306122 %\n",
      " The accuracy for  2  iteration of Cross-Validation is  83.46938775510205 %\n",
      " The accuracy for  3  iteration of Cross-Validation is  83.6734693877551 %\n",
      " The accuracy for  4  iteration of Cross-Validation is  86.12244897959184 %\n",
      " The accuracy for  5  iteration of Cross-Validation is  83.6734693877551 %\n",
      " The accuracy for  6  iteration of Cross-Validation is  84.48979591836735 %\n",
      " The accuracy for  7  iteration of Cross-Validation is  83.46938775510205 %\n",
      " The accuracy for  8  iteration of Cross-Validation is  84.66257668711657 %\n",
      " The accuracy for  9  iteration of Cross-Validation is  82.0040899795501 %\n"
     ]
    }
   ],
   "source": [
    "    K = 10\n",
    "    lst = np.arange(1,10)\n",
    "    accuracy = []\n",
    "    for j in lst:\n",
    "        training_set = [x for i, x in enumerate(data) if i % K != j]\n",
    "        test_set = [x for i, x in enumerate(data) if i % K == j]\n",
    "        my_tree = build_tree(training_set)\n",
    "        results= []\n",
    "        for row in test_set:\n",
    "            result = classify(row, my_tree)\n",
    "            results.append( result == row[-1])\n",
    "        accuracy.append(float(results.count(True))/float(len(results)))\n",
    "        print ( \" The accuracy for \" , j , \" iteration of Cross-Validation is \" , float(results.count(True))/float(len(results))*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average accuracy for Cross-Validation is  83.9606953893 %\n"
     ]
    }
   ],
   "source": [
    "print ( \"The Average accuracy for Cross-Validation is \" , np.average(accuracy)*100 , \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Conclusion</span>\n",
    "\n",
    "#### <span style=\"color:blue\">Above is the startegy 1  for improving the tree's performance . We have implemented Gini Index here instead of Entropy as Information Gain Measure.  The Average accuracy for Cross-Validation is  83.96 % </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"> Strategy 2 :- Pruning the Tree</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Building the Tree recursively  & Prune it after 20 Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Depth_true = 0\n",
    "Depth_False = 0\n",
    "\n",
    "def build_tree_Pruned(rows):\n",
    "    global Depth_true\n",
    "    global Depth_False\n",
    "    gain, Evals_Criteria = find_best_split(rows)\n",
    "    if gain == 0:\n",
    "        return Prediction_Node(rows)\n",
    "    true_rows, false_rows = Splits(rows, Evals_Criteria)\n",
    "    \n",
    "    if Depth_true <= 15 :\n",
    "        true_branch = build_tree(true_rows)\n",
    "        Depth_true += 1\n",
    "    else:\n",
    "        return Prediction_Node(rows)\n",
    "    \n",
    "    if Depth_False <= 15 :\n",
    "        false_branch = build_tree(false_rows)\n",
    "        Depth_False += 1\n",
    "    else:\n",
    "        return Prediction_Node(rows)\n",
    "    \n",
    "    return Decision_Node(Evals_Criteria, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tree_pruned = build_tree_Pruned(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Test set which is  25% of toal Data Set is 82.0040899795501\n"
     ]
    }
   ],
   "source": [
    "results= []\n",
    "for row in test_set:\n",
    "    result = classify(row, my_tree_pruned)\n",
    "    results.append( result == row[-1])\n",
    "    \n",
    "accuracy = float(results.count(True))/float(len(results))\n",
    "print ( \"The Accuracy for Test set which is  25% of toal Data Set is\" , accuracy *100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The accuracy for  1  iteration of Cross-Validation is  84.08163265306122 %\n",
      " The accuracy for  2  iteration of Cross-Validation is  83.46938775510205 %\n",
      " The accuracy for  3  iteration of Cross-Validation is  83.6734693877551 %\n",
      " The accuracy for  4  iteration of Cross-Validation is  86.12244897959184 %\n",
      " The accuracy for  5  iteration of Cross-Validation is  83.6734693877551 %\n",
      " The accuracy for  6  iteration of Cross-Validation is  84.48979591836735 %\n",
      " The accuracy for  7  iteration of Cross-Validation is  83.46938775510205 %\n",
      " The accuracy for  8  iteration of Cross-Validation is  84.66257668711657 %\n",
      " The accuracy for  9  iteration of Cross-Validation is  82.0040899795501 %\n"
     ]
    }
   ],
   "source": [
    "    K = 10\n",
    "    lst = np.arange(1,10)\n",
    "    accuracy = []\n",
    "    for j in lst:\n",
    "        training_set = [x for i, x in enumerate(data) if i % K != j]\n",
    "        test_set = [x for i, x in enumerate(data) if i % K == j]\n",
    "        my_tree = build_tree_Pruned(training_set)\n",
    "        results= []\n",
    "        for row in test_set:\n",
    "            result = classify(row, my_tree)\n",
    "            results.append( result == row[-1])\n",
    "        accuracy.append(float(results.count(True))/float(len(results)))\n",
    "        print ( \" The accuracy for \" , j , \" iteration of Cross-Validation is \" , float(results.count(True))/float(len(results))*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average accuracy for Cross-Validation is  83.9606953893 %\n"
     ]
    }
   ],
   "source": [
    "print ( \"The Average accuracy for Cross-Validation is \" , np.average(accuracy)*100 , \"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Conclusion</span>\n",
    "\n",
    "#### <span style=\"color:blue\">Above is the startegy 2 for improving the tree's performance . We have implemented pruning of the tree here where the depth of the tree doesn't  go beyond 15 .  The Average accuracy for Cross-Validation is  83.96 %  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
